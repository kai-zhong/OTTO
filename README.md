# 项目介绍：基于会话的多目标电商推荐系统 (OTTO)

## **1. 项目背景**

随着电子商务的迅速发展，消费者面临着前所未有的商品选择。尽管商品种类的丰富性极大地提升了购物的可能性，但也带来了信息过载的问题。用户往往难以在海量商品中快速定位到符合自身兴趣和需求的商品，这可能导致购物体验下降，甚至放弃购买。对于电商平台而言，这不仅意味着用户流失，也直接影响到销售转化。因此，构建一个能够高效、精准地将商品推荐给用户的推荐系统，对于优化用户体验和提升平台商业价值至关重要。

当前的推荐系统技术已经取得了显著进展，涵盖了从经典的协同过滤、基于内容的推荐到复杂的深度学习模型等多种方法。然而，许多现有系统倾向于专注于优化单一的推荐目标，例如最大化点击率或预测购买行为。在真实的电商场景中，用户的互动行为是多阶段且复杂的，包括浏览（点击）、将商品加入购物车以及最终完成订单等。如何构建一个能够同时理解并预测用户在这些不同阶段的潜在行为，从而实现多目标的推荐优化是当前推荐系统领域面临的一个重要挑战。

本项目正是为了应对这一挑战而展开，我们基于 OTTO 电商平台提供的真实用户会话数据，旨在开发一个能够准确预测用户在当前会话中后续点击、加入购物车和下单行为的多目标推荐系统。

## **2. 数据分析概要**

本项目所使用的数据集源自 OTTO 电商平台的匿名用户行为日志，是一个专门为基于会话的多目标推荐研究而设计的大规模、真实世界数据集。

数据集的核心结构是用户会话（session），每个会话记录了用户在特定时间段内按时间顺序发生的一系列事件。主要的事件类型包括：

- **clicks (点击)**：表示用户查看了某个商品。
- **carts (加入购物车)**：表示用户将某个商品添加到了购物车。
- **orders (下单)**：表示用户购买了购物车中的商品。

数据集规模庞大，包含了数百万级别的用户会话和超过两亿次的事件记录，涵盖了近两百万种独特的商品。数据提供了详细的会话 ID、商品 ID (aid)、事件发生的时间戳 (ts) 以及事件类型 (type) 等信息。

训练集和测试集采用了基于时间的划分策略，训练集数据覆盖了连续的四周，而测试集则包含了紧随其后的下一周数据。测试集中的用户会话被有意地截断到某个时间点，要求我们根据截断点之前的历史行为来预测用户在截断点之后可能发生的行为。这种设置模拟了实际推荐场景中需要实时预测用户未来行为的需求，同时也增加了任务的挑战性，因为模型需要从有限的历史信息中进行推断。

通过对数据集的统计分析，我们可以了解到会话长度、每个商品被交互的频率等重要分布特征。例如，训练集和测试集的会话平均事件数量、事件类型的分布比例等，这些信息对于后续的数据预处理、特征工程以及模型选择和优化具有重要的指导意义。

## **3. 项目目标**

本项目的核心目标是**利用 OTTO 电商平台的用户会话数据，构建一个高效且精确的多目标推荐系统，能够同时预测用户在会话后续的点击、加入购物车和下单行为。**

具体而言，项目需要实现以下预测任务：

- **预测用户在当前会话中接下来最有可能点击的商品 (aid)。**
- **预测用户在当前会话中接下来可能加入购物车的商品 (aid) 集合。**
- **预测用户在当前会话中接下来可能下单的商品 (aid) 集合。**

对于每种行为类型，我们需要预测最多 20 个相关的商品 ID。

项目的最终评估将采用加权平均的 Recall@20 指标。其中，加入购物车和下单行为的召回率被赋予了更高的权重（0.30 和 0.60），而点击行为的权重相对较低（0.10）。这种加权方式强调了项目在促进用户转化和提升最终销售方面的价值。

通过本项目，我们期望能够：

- 探索并应用先进的基于会话推荐和多任务学习技术。
- 提升电商推荐系统的个性化水平和预测准确性。
- 优化用户在电商平台上的购物路径，提供更流畅、更相关的商品发现体验。
- 为 OTTO 等电商平台提供有价值的技术支持，帮助其提高用户参与度和商业收益。

## **4. 评估方法**

提交结果将根据每种操作类型的 **Recall@20** 进行评估，并采用加权平均计算最终得分：
$$
score=0.10⋅R_{clicks}+0.30⋅R_{carts}+0.60⋅R_{orders}
$$
其中，Rtype 定义如下：
$$
R_{type}=\frac{\sum_i^N|\{\text{predicted aids}\}_{i,type}\cap\{\text{ground truth aids}\}_{i,type}|}{\sum_i^N\min\left(20,|\{\text{ground truth aids}\}_{i,type}|\right)}
$$
其中：

- N 表示测试集中会话的总数。
- 预测的 aid 是针对每个会话-操作类型的预测结果（即提交文件中的每一行），最多包含前 20 个预测值。

对于测试数据中的每个会话，你的任务是预测在测试会话的最后时间戳 ts 之后发生的 aid 值。

- 对于**点击（clicks）**，每个会话只有一个真实值，即该会话中接下来的点击 aid（但你仍然可以预测最多 20 个 aid 值）。
- 对于**购物车（carts）和 订单（orders）**，真实值包含该会话期间加入购物车和下单的所有 aid。

## **5. 方法实现**

本节将详细介绍项目的代码实现过程，主要分为以下几个部分：数据准备、共现矩阵召回、特征构建和 LightGBM 召回。

### **5.1 数据准备**

数据准备阶段是构建推荐系统的基础，它涉及对原始数据进行清洗、转换和特征提取，以便于后续的模型训练。在本项目中，数据准备主要包括生成用户和物品的嵌入向量以及进行聚类。本节将首先介绍如何使用 BPR 方法生成嵌入向量。

#### **5.1.1 使用 BPR 方法生成用户和物品嵌入**

**方法介绍：BPR (Bayesian Personalized Ranking)**

BPR（Bayesian Personalized Ranking）是一种基于成对比较的隐式反馈推荐算法。它通过最大化后验概率来学习用户和物品的低维潜在向量表示。BPR 的核心思想是，对于用户发生过交互的物品，其被用户喜欢的概率应该大于用户未交互过的任意物品。算法通过优化一个排序损失函数来学习这些向量，使得在用户-物品交互矩阵中，观察到的交互对 (用户, 交互物品) 的预测分数高于未观察到的对 (用户, 未交互物品)。学习到的用户和物品嵌入向量能够捕捉用户偏好和物品特征中的潜在模式。

**实现过程：**

该部分代码使用 `implicit` 库实现了 BPR 模型，并利用训练数据学习用户和物品的嵌入向量。

**输出数据：**

代码的输出是两个 Python pickle 文件，分别存储了用户和物品的嵌入向量，如果用户的embedding与物品的embedding做点积，其值越大，说明该用户对该物品的兴趣值越大：

- `u2emb.pkl`: 存储用户嵌入向量的字典。字典的键是原始的 `session` ID，值是对应的用户嵌入向量（一个 NumPy 数组）。嵌入向量的维度由 `emb_size` 参数决定（代码中设置为 64），此外还包含一个偏置项，所以向量维度是 `emb_size + 1`。
- `i2emb.pkl`: 存储物品嵌入向量的字典。字典的键是原始的 `aid`，值是对应的物品嵌入向量（一个 NumPy 数组）。同样，嵌入向量的维度是 `emb_size + 1`。

这些嵌入向量是对用户和物品潜在特征的数值表示，可以在后续的特征工程和模型训练中作为重要的输入特征。

#### 5.1.2 使用 Word2Vec 方法生成商品嵌入

**方法介绍：Word2Vec**

Word2Vec 是一种常用的词嵌入技术，它能够将文本中的词语映射到低维向量空间中，使得语义相似的词语在向量空间中距离更近。在推荐系统中，我们可以将用户会话中的商品序列类比于自然语言处理中的句子，将会话中的商品 ID 类比于词语。通过对大量用户会话序列应用 Word2Vec 模型，我们可以学习到商品的嵌入向量，这些向量能够捕捉商品之间的共现关系和潜在的关联性。

**实现过程：**

该部分利用 `gensim` 库实现了 Word2Vec 模型，并使用用户会话中的商品点击序列作为训练数据来学习商品的嵌入向量。

**输入数据：**

将训练集和测试集数据过滤出类型为“clicks”的事件，然后将每个会话中的商品 ID 序列组织成一个列表，作为 Word2Vec 模型的输入“句子”。所有的“句子”构建成word2vec的训练集，来训练每个商品的embedding。

**输出数据：**

输出是存储了商品的嵌入向量的dataframe。文件包含以下列：

- `aid`: 商品的唯一 ID。
- `vec_0`, `vec_1`, ..., `vec_dims-1`: 对应的商品嵌入向量的各个维度。

这些商品嵌入向量可以在后续的特征工程中用于表示商品，或者用于计算商品之间的相似度。

一共生成了商品16 dims的embedding和64dims的embedding。

#### 5.1.3 使用聚类方法对商品进行分组

**方法介绍：Leiden 聚类**

Leiden 算法是一种用于社区检测（Community Detection）的图聚类算法。它基于模块度优化，旨在将图中的节点划分为不同的社区或簇，使得同一社区内的节点连接紧密，而不同社区之间的连接相对稀疏。在推荐系统中，我们可以将商品视为节点，商品之间的相似性（例如基于嵌入向量的相似度）视为边的权重，然后应用聚类算法将相似的商品分组到一起。这些商品簇可以用于生成多样化的推荐列表，或者作为额外的特征。

在该部分实现中，我们结合使用了 `scanpy` 库，它是一个用于单细胞基因组学数据分析的工具，但其强大的图构建和聚类功能也可以应用于其他领域的数据分析，如这里的商品嵌入向量聚类。

**实现过程：**

该部分代码首先加载 Word2Vec 生成的商品嵌入向量，然后使用 `scanpy` 库构建商品的 k 近邻图（即连接每个商品在向量空间中最相似的k个邻居（K是由用户给定的）），该k近邻图是一个有权图，最后应用 Leiden 算法依据边权重对商品进行聚类。

**输入数据：**

输入是 Word2Vec 方法生成的商品嵌入向量文件，存储在 `.parquet` 格式中。文件应包含商品 ID (`aid`) 和其对应的嵌入向量。

**输出数据：**

输出是一个 `.parquet` 文件，存储了商品 ID 及其对应的聚类标签。文件包含以下两列：

- `aid`: 商品的唯一 ID。
- `cluster`: 商品所属的聚类标签（一个整数）。

这些聚类标签可以将商品划分为不同的组别，可以在后续的特征工程中作为类别特征使用。

### 5.2 共现矩阵召回

共现矩阵召回是本项目中的一个重要召回策略，它基于用户在会话中连续或同时交互的商品来发现商品之间的关联性。通过构建不同类型和权重的共现矩阵，我们可以从用户历史行为中挖掘出丰富的商品关联信息，并为测试集中的每个会话生成相关的候选商品列表。

#### **整体流程：**

**共现矩阵召回的整体流程如下：**

1. **提取用户行为特征（用户特征）：** 包含以下用户行为特征：

   - **每个用户最后一次交互的商品**，每行包含：
     - session ：用户 id号
     - aid : 当前用户最后一次事件交互的商品ID
   - **每个用户的热门点击商品**，每行包含：
     -  session : 用户 id号
     -  aid : 当前用户中被点击的次数位于前30%的商品ID
   - **每个用户最后一次事件发生前一小时内的交互商品(不包含最后一次交互的商品)**，每行包含：
     -  session : 用户 id号
     -  aid : 当前用户最后一次交互发生前一个小时内交互的商品ID(不包含最后一次交互的商品id)
   - **每个用户最后一次事件发生前一天内的交互商品(不包含最后一小时内交互的商品)**，每行包含：
     -  session : 用户 id号
     -  aid : 当前用户最后一次交互发生前一天内交互的商品ID(不包含最后一小时交互的商品id)
   - **每个用户中被加购和购买的商品**，每行包含：
     - session : 用户 id号
     - aid : 当前用户中被加购或购买的商品id

   | 数据名             | 描述                                    | 包含列           |
   | ------------------ | --------------------------------------- | ---------------- |
   | `data_last_action` | 每个会话的最后一次操作的商品            | `session`, `aid` |
   | `data_top_click`   | 每个会话中点击次数最多的商品（前30%）   | `session`, `aid` |
   | `data_last_hour`   | 最近1小时内的点击记录（不包含最后操作） | `session`, `aid` |
   | `data_last_day`    | 最近1天内的点击记录（不包含最近1小时）  | `session`, `aid` |
   | `data_cart_or_buy` | 所有加购/下单的商品                     | `session`, `aid` |

2. **计算商品转化率 (CVR)（商品特征）：**

   - **商品转化率相关特征：**

     - aid : 商品ID
     - click_n :  点击过该商品的用户数（一个用户多次点击也只算一次）
     - cart_n : 既点击过该商品又存在加购行为（加购别的商品也算）的用户数
     - cart_cvr : 弱CVR指标， $CVR = cart_n / click_n$，即点击该商品的用户中，有多少比例存在加购行为。==（cvr指标并非是用于预测用户是否会交互这件商品，这个特征是针对推荐系统的，对于推荐系统来说，如果两件商品对于一个用户具有相同的推荐分数，那么肯定更愿意推荐转化率高的商品给用户，那么用户也就更可能与这些商品进行交互）==

   - ==**特殊处理**==：低频商品的平滑处理，对点击次数低于 4 的商品，将其原始 `cart_cvr` 乘以全局均值，避免小样本下 CVR 不稳定。这么做的原因是低频商品的原始转化率（CVR）很容易出现**“极端值”或“虚高/虚低”**，从而影响模型判断。

     - **例子：**当一个商品只有 1 次点击，恰好被加购了：
       $$
       \text{CVR} = \frac{1}{1} = 1.0
       $$
       这会让人以为这个商品转化率超高，但其实是“样本太少”导致的不稳定。

       而另一个商品有 1000 次点击，100 次加购：
       $$
       \text{CVR} = \frac{100}{1000} = 0.10
       $$
       尽管它转化率只有 0.1，但它是**非常可信的指标**。

       ==因此，通过把原来的 `cart_cvr` 乘上整体平均 `cart_cvr`，降低极端值影响。==

   - ==**问题：**为什么使用弱 CVR 指标，而不使用的是一个商品被点击后被加购的用户数除以点击的用户数。==

     - **理由1、点击 → 购买 是用户意图的链式行为：**相较于关心一个商品在被点击后被加购的可能性，我们更关心的是一个商品在被点击之后，用户是否会存在加购行为。这相比与前者，更能够反应这个商品是否具有吸引用户加购的能力。这种能力可能来源于多种情况，比如用户能够通过该物品发现一些感兴趣的物品等等。

       如果用户点击了一个商品，**随后发生了加购行为**（即使加购了别的商品），这说明：

       - 这个商品的曝光或推荐是“成功触达了目标用户”的；
       - 反映了该商品 **触发购买意图的能力**。

       这个特征我们用于判断加购的可能程度，举例来说，一个用户最后一次交互是点击了商品A，而商品A存在很高的弱CVR指标，

     - **理由2、稀疏性问题，真实加购本商品的人太少：**

       - 大部分商品点击之后不会被直接加购；
       - 如果用“是否加购了该商品本身”来算，CVR 大多是 0，极度稀疏；
       - 用“是否会话中出现任何加购”作为代理，会让 **转化数据更密集、稳定**，尤其适合早期特征建模。

     - **理由3、模型召回阶段更关注兴趣，而非精准因果：**

       - 在**粗排/召回阶段**，我们不是特别需要精确度，而更在意：
         - 哪些商品能吸引那些**具有加购倾向的用户**；
         - 哪些商品经常出现在“转化型会话”中；
       - 精准转化率更适合用在 **精排模型**中做 final scoring。

3. **配置共现矩阵构建模式：** 定义多种共现矩阵的构建模式，每种模式又包括了不同的事件类型组合（如点击-点击、点击-购买，==**即规定共现对src物品的类型与dst物品的类型**==）、时间窗口限制（如一小时内）、是否考虑重复事件以及是否使用 Word2Vec 嵌入等。

   **共定义了8中不同的共现模式（模式名）：**

   注：对于共现对(aid_x, aid_y)，session与aid_x交互的时间戳记为ts_x，与aid_y交互的时间戳记为ts_y

   | 模式名      | 共现对筛选条件                                               | 共现分数计算方式                                             |
   | ----------- | :----------------------------------------------------------- | ------------------------------------------------------------ |
   | `allterm`   | 无筛选条件，但对于同一session中多次出现的共现对(aid_x,aid_y)，只保留一对 | 因为去重过：==**共现分数=aid_x和aid_y共同出现的session数/与aid_x交互过的session总数。**==（可以理解为aid_y与aid_x共现的session数占aid_x总出现的session数的比例，即aid_y与aid_x的相关性） |
   | `dup`       | 无筛选条件，不对同一session中多次出现的共现对去重            | 因为未去重过，==**共现分数=aid_x和aid_y总共现的次数（包括同一session中多次共现）/aid_x总出现的次数(包括同一session中多次出现)**== |
   | `dup_wlen`  | 与 `dup` 相同                                                | diff_ts = abs(ts_y - ts_x)，按照diff_ts从小到大排序，aid_x与aid_y之间相差时间越小排序越靠前，排名rank越小，==**共现分数=（aid_x,aid_y）共现对在所有session中的rank/aid_x总出现的次数(包括同一session中多次出现)**== |
   | `dup_hour`  | 仅保留满足[0 < ts_y - ts_x < 1小时]的共现对，不对同一session中多次出现的共现对去重 | 与 `dup` 相同                                                |
   | `base`      | 仅保留满足[0 < ts_y - ts_x]的共现对，需要进行去重            | 与`allterm`相同                                              |
   | `base_wlen` | 与 `base` 相同                                               | diff_ts = abs(ts_y - ts_x)，按照diff_ts从小到大排序，aid_x与aid_y之间相差时间越小排序越靠前，排名rank越小，==**共现分数=（aid_x,aid_y）共现对在所有session中的rank/与aid_x交互过的session总数**== |
   | `base_hour` | 仅保留满足[0 < ts_y - ts_x < 1小时]的共现对，需要进行去重    | 与`allterm`相同                                              |
   | `w2v`       | 与其他模式不同，其他模式下共现对的生成来源于商品在同一session中被交互，而w2v模式下，商品根据其w2v的embedding使用KNN方法找到最相近的k个邻居商品，即为每个商品生成k个共现对 | aid_x与aid_y的embeding的余弦距离(余弦距离=1-余弦相似度)      |

4. **构建共现矩阵和自关联特征（一对商品在同一个session中出现，那么这一对商品称为一对共现商品对）：** **步骤：** 

   1. **商品对筛选：**逐个使用上面配置的8种模式，根据模式的共现对筛选条件与不同事件类型组合的限制，从所有商品对中挑选出符合条件的商品对
   2. **高低频商品划分：**对这些符合条件的商品共现对计算每个商品作为src商品的次数（即属于该商品的共现对数），根据给定的阈值，将小于阈值的商品划分为低频商品，大于阈值的商品划分为高频商品
   3. **共现分数计算：**根据每种模式的共现分数计算方式，计算每个共现对的共现分数，然后对于每个aid_x，给他的aid_y们按照共现分数的大小给一个排名，只保留前cut_rank个共现对。
   4. **数据增强：**对于每个src商品aid_x，取他共现分数排名前三的共现商品aid_y，如果aid_y属于高频商品，则将以aid_y为src商品的共现对的dst商品aid_z也与aid_x组建成共现对，新共现对(aid_x, aid_z)的共现分数等于xy的共现分数乘以yz的共现分数。==通过这样数据增强，可以找到潜在的共现关系。使用高频物品作为中间物品而不使用低频物品的原因是，高频物品的数据量更大，他的属性和与aid_x的共现强度更稳定更接近正确，而低频物品数据量较少，统计出来的共现分数往往不稳定，存在较大波动。若用这些物品作为“桥梁”扩展关系，容易引入无意义甚至错误的共现关系。==
   5. **提取自关联矩阵：**自关联矩阵即为共现矩阵中aid_x=aid_y的共现对组成的矩阵。==另一个不使用强CVR的原因是，在allterm模式下，click-buy自关联矩阵的share分数即为强CVR值，因此无需重复计算。==

5. **生成召回候选集：** 基于生成的共现矩阵和用户的行为特征（如最后一次点击的商品，==**即以这些行为特征来代表用户特征，寻找与用户特征相似的商品作为召回结果**==），为测试集中的每个会话生成一个相关的商品列表作为召回候选集。不同的行为特征和不同的共现矩阵模式会生成不同的召回候选集。比如使用data_last_action作为行为特征，allterm-click-click作为共现矩阵，就能生成一组召回候选集，最后一共会为每个session生成 【行为特征数×事件类型组合数×共现矩阵模式数】（具体看代码中的配置，比如w2v就只有click-click一种事件类型组合）个召回候选集。

   **具体步骤（以用`data_last_hour`作为行为特征为例）：**

   1. 将行为特征中的aid作为aid_x与共现矩阵拼接，得到每个session最后一小时交互的商品的共现对(aid,aid_y)，然后在每个session中，计算aid_y的总得分，这个总得分等于所有以aid_y为dst商品的共现对的共现分数之和（最后一小时中交互的物品可能有很多存在与aid_y共现的，将这些共现对的共现分数加起来以得到aid_y的总得分）。然后在session中对于所有的aid_y，按总得分排序，取前K(自己指定的截断)个aid_y作为该行为特征下使用某个共现矩阵的召回结果。

6. **生成最终召回结果：**为click,cart,order分别配置config，设置从每个召回候选集$R$中选取的截断排名$k_R$，配置好后，从每个召回候选集中选取共现分数排名前k的商品，将从各个召回候选集中获取的商品汇集在一起作为最终的召回结果。

#### 输出数据：

**该部分的主要输出数据包括：**

**召回候选集 ：** 存储每个session的候选商品，以及这些候选商品在这个session中的得分

- session: session ID。

- aid: 商品 ID 。

- share: 得分。

- cart_cvr (非 Word2Vec 模式)：aid_y 的点击到购物车的弱转化率。


**自关联特征矩阵：**存储自己到自己的一些特征，从共现矩阵中提取出来的，后续作为排序时的物品特征。

**共现矩阵结果与意义说明：**

构建的共现矩阵是商品之间关联性的重要体现。不同的共现矩阵模式捕捉了不同类型的商品关联：

- **allterm 模式：** 统计在同一个会话中任意位置出现的商品对的共现次数，反映了商品在会话中的整体关联性，不考虑时间顺序。
- **dup 模式：** 统计在同一个会话中重复出现的商品对的共现次数，即使它们出现多次也会被重复计数，反映了商品在会话中的频繁共现程度。
- **dup_wlen 模式：** 在 dup 模式的基础上，考虑商品对出现的时间差，时间差越小的商品对权重越高，反映了商品在时间上更紧密的关联。
- **dup_hour 模式：** 在 dup 模式的基础上，仅考虑在一小时内出现的商品对，反映了商品在短时间窗口内的关联性。
- **base 模式：** 仅统计满足时间顺序的商品对的共现次数（即商品 Y 在商品 X 之后出现），反映了商品在会话中的顺序关联性。
- **base_wlen 模式：** 在 base 模式的基础上，考虑时间差权重，时间差越小的商品对权重越高，反映了商品在顺序关联中的时间紧密度。
- **base_hour 模式：** 在 base 模式的基础上，仅考虑在一小时内且满足时间顺序的商品对，反映了商品在短时间窗口内的顺序关联性。
- **w2v 模式：** 基于 Word2Vec 嵌入向量计算商品之间的相似度（余弦距离），相似度越高（距离越小）的商品关联性越强，反映了商品在语义或功能上的相似性。
- **共现矩阵中的 share 值**：衡量 aid_x 和 aid_y 之间关联强度的核心指标。对于基于次数或权重的共现矩阵，share 通常表示 aid_x 和 aid_y 的共现次数或权重和除以 aid_x 的总共现次数，可以理解为从 aid_x 转移到 aid_y 的概率或强度。对于 Word2Vec 模式，share 是余弦距离，值越小表示相似度越高。
- **cart_cvr 列（非 Word2Vec 模式）：**提供了目标商品 aid_y 的转化率信息，这在生成召回候选集时可以作为辅助排序的依据，优先推荐转化率较高的相关商品。
- **自关联特征 same_{start_type}_{end_type}_{pattern}：** 捕捉了商品自身的行为模式，例如一个商品被点击后有多大概率被购买。这些特征可以在后续的特征构建阶段用于更精细地描述商品或用户-商品对。

clicks的召回集合：每行包含两列，session和aid，aid是为session召回的click商品。

carts的召回集合：每行包含两列，session和aid，aid是为session召回的cart商品。

orders的召回集合：每行包含两列，session和aid，aid是为session召回的order商品。

all的召回集合：每行包含两列，session和aid，aid是为session召回的all商品（==all是指发生过交互的商品，不区分类别==）。

### 5.3 特征构建

#### 5.3.1 bigram-feature

**转移分数：**转移分数的计算是基于所有用户会话中的商品序列。对于任意两个商品 A 和 B，它们之间的转移分数衡量了在所有会话中，商品 A 后面紧跟着商品 B 出现的频率。计算步骤如下：

1. **识别相邻商品对：** 遍历所有用户会话，对于每个会话中的商品序列，识别所有相邻的商品对 (A,B)，其中 A 是当前商品，B 是紧随其后的商品。

2. **统计商品对出现次数：** 统计所有识别出的商品对 (A,B) 在整个数据集中出现的总次数 Count(A,B)。

3. **统计单个商品出现次数：** 统计商品 A 在整个数据集中出现的总次数 Count(A)，以及商品 B 在整个数据集中出现的总次数 Count(B)。

4. **归一化计算转移分数：** 采用归一化方法计算商品对 (A,B) 的转移分数。本项目中使用的归一化公式为：
   $$
   Score_{transition}(A,B) = \frac{Count((A,B))}{\sqrt{Count(A)\cdot Count(B)}}
   $$
   ==这个归一化方法考虑了商品 A 和商品 B 各自的流行度。通过除以它们出现次数乘积的平方根，可以减轻非常流行的商品对由于高频出现而导致转移分数过高的问题，使得转移分数更能反映商品之间的真实关联性，而非仅仅是商品自身的流行度。==

**构建的特征：**

为每个会话中的召回**order候选商品**构建了一系列 **会话-order候选商品对特征**，具体包括：

- **与会话历史点击商品的 Bigram 转移分数统计特征(columns=[session, aid(order), score_trans])：**
  - `bigram_normed_click_sum`: 对于一个order候选对（sessionA, aid_o），order候选商品aid_o作为转移目标商品B，与sessionA的历史所有click商品之间转移分数的总和。
  - `bigram_normed_click_mean`: 对于一个order候选对（sessionA, aid_o），order候选商品aid_o作为转移目标商品B，与sessionA历史所有click商品之间转移分数的平均值。
  - `bigram_normed_click_max`: 对于一个order候选对（sessionA, aid_o），order候选商品aid_o作为转移目标商品B，与sessionA历史所有click商品之间转移分数中的最大值。
  - `bigram_normed_click_min`: 对于一个order候选对（sessionA, aid_o），order候选商品aid_o作为转移目标商品B，与sessionA历史所有click商品之间转移分数中的最小值。
  - `bigram_normed_click_last`: 对于一个order候选对（sessionA, aid_o），order候选商品aid_o作为转移目标商品B，与sessionA中最后一个click商品之间的转移分数。
- **与会话历史加购商品的 Bigram 转移分数统计特征：**
  - `bigram_normed_cart_sum`: 对于一个order候选对（sessionA, aid_o），order候选商品aid_o作为转移目标商品B，与sessionA的历史所有cart商品之间转移分数的总和。
  - `bigram_normed_cart_mean`: 对于一个order候选对（sessionA, aid_o），order候选商品aid_o作为转移目标商品B，与sessionA历史所有cart商品之间转移分数的平均值。
  - `bigram_normed_cart_max`: 对于一个order候选对（sessionA, aid_o），order候选商品aid_o作为转移目标商品B，与sessionA历史所有cart商品之间转移分数中的最大值。
  - `bigram_normed_cart_min`: 对于一个order候选对（sessionA, aid_o），order候选商品aid_o作为转移目标商品B，与sessionA历史所有cart商品之间转移分数中的最小值。
  - `bigram_normed_cart_last`: 对于一个order候选对（sessionA, aid_o），order候选商品aid_o作为转移目标商品B，与sessionA中最后一个cart商品之间的转移分数。

**特征解释：**这些 Bigram 特征基于商品之间的“转移分数”计算得出。转移分数衡量了在一个会话中，一个商品后面紧跟着另一个商品出现的可能性，这里通过基于一个session的click和cart历史，衡量一个order候选物品将在后续被order的可能性。

#### 5.3.2 BPR特征

**BPR特征：**session的embedding与召回的aid的embedding的点积。

对于click,cart,order的召回候选集，对于每一对(session, aid)，计算session的BPR embedding向量和aid的BPR embedding向量的点积，点积越大说明两个向量越相似，session对aid的兴趣分数越大。

#### 5.3.3 cluster 特征

**cluster特征：**该特征是对于一个召回候选对(sessionA, aid_x)来说，sessionA的历史交互列表中最后一次交互的aid所属的商品聚类到aid_x所属的商品聚类的共现概率。

**聚类共现概率的计算：**对于每一个聚类对$(cluster_i, cluster_j)$，计算属于$cluster_i$的商品与属于$cluster_j$商品的共现的数量占属于$cluster_i$的商品的共现总数的比例。

#### 5.3.4 w2v特征

对于每中行为召回候选集，分别使用商品的w2v 16维embedding和64维embedding分别各生成了3组特征。一共24（4种行为候选集（click,cart,order,all）×2种维度×3种特征）组特征分别是：

1. **Session 级别的 W2V 距离特征（以session所有历史物品embedding作为session的embeding）：**
   - **核心思想**：将session历史交互的所有物品的embedding做平均，作为该session的w2v embedding向量，然后计算候选商品 `aid` 的 W2V embedding向量 与 该商品所属 `session` 的embedding向量之间的余弦相似度。
   - **Session 平均向量的计算**：对于一个 `session`，找出其中所有交互过的商品 `aid`，获取它们的 W2V 向量，然后计算这些向量的**平均值**，以此代表该 `session` 的整体兴趣或表征。
   - **特征含义**：衡量一个候选商品与用户当前会话整体兴趣的匹配程度。值越高，表示该商品与会话中其他商品的整体语义越相似。
2. **Last Aid 级别的 W2V 距离特征（以session最后一次交互物品的embedding作为session的embeding）：**
   - **核心思想**：将session最后一次交互物品的embedding作为session的embeding，然后计算候选商品 `aid` 的 W2V embedding向量与该商品所属 `session` 的embedding向量之间的余弦相似度。
   - **特征含义**：衡量候选商品与用户会话**最终交互**商品的相似度。这对于预测紧接着发生的行为可能很有用。
3. **Last hour Aid 级别的 W2V 距离特征（以session最后一小时交互物品的embedding的均值作为session的embeding）：**
   - **核心思想**：将session最后一小时交互物品的embedding的均值作为session的embeding，然后计算候选商品 `aid` 的 W2V embedding向量与该商品所属 `session` 的embedding向量之间的余弦相似度。
   - **特征含义**：衡量候选商品与用户会话**近期（非最后）**交互商品的相似度。这反映了用户在结束会话前的近期兴趣范围。

#### 5.3.5 商品日期特征

这些特征描述了在数据集中，每个商品 (`aid`) 在特定日期 (`day`) 的活动情况。

包含以下特征：

- `day` (int): 年份中的第几天 (1-366)。
- `daily_aid_share` (float32): **商品日互动占比**
  - **计算**: (此 `aid` 在此 `day` 的互动次数) / (此 `day` *所有* `aid` 的总互动次数)。
  - **意义**: 代表该商品在特定日期占所有用户活动的份额。值越高表示该商品相对于当天其他商品的互动频率更高。
- `aid_day_inter_session_ratio` (float32): **商品日互动 Session 占比 (任意类型)**
  - **计算**: (在此 `day` 与此 `aid` 互动的独立 session 数量) / (此 `day` 发生过交互的总独立 session 数量) 。
  - **意义**: 代表当天活跃的 session 中，有多少比例至少与该特定商品互动过一次。
- `aid_day_cart_session_ratio` (float32): **商品日加购物车 Session 占比**
  - **计算**: (在此 `day` 将此 `aid` 加入购物车 的独立 session 数量) / (此 `day` 有加购物车行为*的总独立 session 数量) 。
  - **意义**: 代表当天有“加购物车行为”的 session 中，有多少比例包含了将此特定商品加入购物车。
- `aid_day_order_session_ratio` (float32): **商品日下单 Session 占比**
  - **计算**: (在此 `day` 购买此 `aid` 的独立 session 数量) / (此 `day` 有下单行为* 的总独立 session 数量) 。
  - **意义**: 代表当天有“下单行为”的 session 中，有多少比例包含了购买此特定商品。

#### 5.3.6 Session 层级特征 

这些特征描述了数据集中，每个用户 `session` 内部的特征与行为。

**基本 Session 信息:**

1. `session` (int): Session ID。
2. `aid` (int): Session 中**最后**互动的商品 ID。
3. `day` (int): Session 中**最后**一次互动发生的年份日期。
4. `last_type` (int): Session 中**最后**一次互动的类型 (0:click, 1:cart, 2:order)。
5. `session_hour_last` (int): Session 中**最后**一次互动发生的小时 (0-23)。
6. `session_dow_last` (int): Session 中**最后**一次互动发生的星期几 (0:周一 - 6:周日)。

**整体 Session 统计:** 

7. `all_counts` (int): Session 中的总互动次数 (clicks+carts+orders)。 
8. `click_ratio` (float32): (点击次数) / `all_counts`。 点击次数占比
9. `cart_ratio` (float32): (加购物车次数) / `all_counts`。 加购次数占比
10. `order_ratio` (float32): (下单次数) / `all_counts`。 下单次数占比
11. `session_cart_cvr` (float32): **会话点击-加购转化率**: (加购物车次数) / (点击次数)。 
12. `session_order_cvr` (float32): **会话加购-下单转化率**: (下单次数) / (加购物车次数)。

**最近 24 小时 Session 统计 (相对于最后一次互动):** 

13. `lastday_all_counts` (int): Session 最后一次互动前的 24 小时内的总互动次数。 
14. `lastday_click_ratio` (float32): 最近 24 小时内的点击比例。 
15. `lastday_cart_ratio` (float32): 最近 24 小时内的加购物车比例。 
16. `lastday_order_ratio` (float32): 最近 24 小时内的下单比例。 
17. `lastday_session_cart_cvr` (float32): 最近 24 小时内的点击-加购转化率。 
18. `lastday_session_order_cvr` (float32): 最近 24 小时内的加购-下单转化率。

**其他 Session 指标:** 

19. `nunique_aids` (int): Session 中互动过的独立商品 ID 数量。 
20. `count_per_ts` (float32): **平均互动耗时**: `ts_length` (session 持续时间，小时) / `all_counts`。每次互动事件的平均时间长度。 
21. `count_per_aids` (float32): **互动商品丰富度**: `nunique_aids` / `all_counts`。互动过的独立商品数与总互动数的比例。越高表示相对于 session 长度探索了更多样化的商品。 
22. `ts_per_length` (float32): **平均互动时间间隔**: `ts_length` (session 持续时间，小时) / `ts_nunique` (独立互动时间戳的数量)。不同互动时刻之间的平均时间长度。

#### 5.3.7 商品层级特征

该函数主要计算历史统计特征与一些近期特征。

1. `aid` (int): **商品 ID**。作为所有特征的主键。

**历史会话转化率 :** 

2. `cart_hist_cvr` (float): **历史点击-加购转化率 (Session 级别)**: (点击 *且* 加购此 `aid` 的 Session 数量) / (点击此 `aid` 的 Session 数量)。衡量历史上点击该商品的用户有多大概率会将其加入购物车。 
3. `order_hist_cvr` (float): **历史点击-下单转化率 (Session 级别)**: (点击 *且* 下单此 `aid` 的 Session 数量) / (点击此 `aid` 的 Session 数量)。衡量历史上点击该商品的用户有多大概率会购买它。

**商品内事件转换比例与时间差 :**

**转换比例**: 这些特征衡量同一个 `aid` 在同一个 session 内，连续两次交互之间类型转换的倾向。 

4. `aid_click_click_ratio` (float): **商品内 Click->Click 转换比例**。 
5. `aid_cart_click_ratio` (float): **商品内 Click->Cart 转换比例**。 
6. `aid_order_click_ratio` (float): **商品内 Click->Order 转换比例**。 
7. `aid_click_cart_ratio` (float): **商品内 Cart->Click 转换比例**。 
8. `aid_cart_cart_ratio` (float): **商品内 Cart->Cart 转换比例** (重复加购)。 
9. `aid_order_cart_ratio` (float): **商品内 Cart->Order 转换比例**。 
10. `aid_click_order_ratio` (float): **商品内 Order->Click 转换比例**。 
11. `aid_cart_order_ratio` (float): **商品内 Order->Cart 转换比例**。 
12. `aid_order_order_ratio` (float): **商品内 Order->Order 转换比例** (重复下单)。

**转换总数与份额**: 

13. `cvr_sum` (int): **商品内总转换次数**: 该 `aid` 在所有 session 中发生的所有类型内部转换的总次数。 
14. `cvr_sum_share` (float): **商品转换活跃度**: 此 `aid` 的 `cvr_sum` / 所有 `aid` 的 `cvr_sum` 总和。反映该商品内部转换行为占所有商品内部转换的比例。

**转换平均时间差 (小时)**: 

15. `aid_click_click_diffts` (float): **商品内 Click->Click 平均时间差**。 
16. `aid_click_cart_diffts` (float): **商品内 Click->Cart 平均时间差**。 
17. `aid_cart_click_diffts` (float): **商品内 Cart->Click 平均时间差**。 
18. `aid_cart_order_diffts` (float): **商品内 Cart->Order 平均时间差**。

**跳过 (Skip) 行为比例 :** 

19. `cart_click_skip_ratio` (float): **加购跳过点击比例**: (未经点击就加购 `aid` 的 Session 数) / (加购 `aid` 的总 Session 数)。衡量用户不看详情直接加购该商品的倾向。 
20. `order_click_skip_ratio` (float): **下单跳过点击比例**: (未经点击就下单 `aid` 的 Session 数) / (下单 `aid` 的总 Session 数)。 
21. `order_cart_skip_ratio` (float): **下单跳过加购比例**: (未经加购就下单 `aid` 的 Session 数) / (下单 `aid` 的总 Session 数)。衡量用户不经过购物车直接购买该商品的倾向。

**基于唯一会话数的统计与转化率:** 

22. `click_session` (int): 点击过该 `aid` 的独立 Session 总数。 
23. `cart_session` (int): 加购过该 `aid` 的独立 Session 总数。 
24. `order_session` (int): 下单过该 `aid` 的独立 Session 总数。 
25. `click_cvr_unique` (float): **商品点击 Session 占比 (对数值)**: `log`((点击该 `aid` 的独立 Session 数) / (数据集中总独立 Session 数))。衡量商品被多少比例的独立会话触达过 (取对数)。*（注意：代码实现的分母是总 session 数，其含义更接近覆盖率）* 
26. `cart_cvr_unique` (float): **唯一会话点击-加购转化率**: `cart_session / click_session`。 
27. `order_cvr_unique` (float): **唯一会话加购-下单转化率**: `order_session / cart_session`。 
28. `click_order_cvr_unique` (float): **唯一会话点击-下单转化率**: `order_session / click_session`。

**基于总事件数的统计与转化率 :** 

29. `click_n` (int): 该 `aid` 被点击的总次数。 
30. `cart_n` (int): 该 `aid` 被加入购物车的总次数。 
31. `order_n` (int): 该 `aid` 被下单的总次数。 
32. `cart_cvr` (float32): **事件数点击-加购转化率**: `cart_n / click_n`。 
33. `order_cvr` (float32): **事件数加购-下单转化率**: `order_n / cart_n`。 
34. `click_order_cvr` (float32): **事件数点击-下单转化率**: `order_n / click_n`。

**重复交互比例:** 

35. `click_repeat_ratio` (float): **点击重复率**: `click_session / click_n`。值越小表示单个 Session 内重复点击越多。 
36. `cart_repeat_ratio` (float): **加购重复率**: `cart_session / cart_n`。 
37. `order_repeat_ratio` (float): **下单重复率**: `order_session / order_n`。

**基于测试/验证集的转化率 :** 

38. `cart_cvr_test` (float32): **测试集点击-加购转化率**: 基于 `test_actions` 计算的 `cart_n / click_n`。反映近期的转化表现。 
39. `order_cvr_test` (float32): **测试集加购-下单转化率**: 基于 `test_actions` 计算的 `order_n / cart_n`。反映近期的转化表现。

**事件份额/流行度 :**

**全局流行度:** 

40. `click_share_all` (float): **全局点击份额**: 该 `aid` 点击次数占所有 `aid` 总点击次数的比例。 
41. `cart_share_all` (float): **全局加购份额**: 该 `aid` 加购次数占所有 `aid` 总加购次数的比例。
42. `order_share_all` (float): **全局下单份额**: 该 `aid` 下单次数占所有 `aid` 总下单次数的比例。

**近期流行度:** 

43. `click_share_test` (float): **测试集点击份额**。 
44. `cart_share_test` (float): **测试集加购份额**。 
45. `order_share_test` (float): **测试集下单份额**。

**其他时间相关特征 :** 

46. `aid_next_diff_mean` (float): **同 Session 内商品交互平均间隔 (秒)**: 对同一个 `aid` 在同一个 session 内连续两次出现的时间间隔取平均值（对所有 session 取平均）。 
47. `aid_rank_mean` (float): **商品 Session 内平均出现排名**: 该 `aid` 在其出现的所有 session 中，按时间顺序首次出现的平均排名（第几个被交互）。 
48. `aid_last_action_diff` (float): **商品最后活跃距今时间 (小时)**: 该 `aid` 最后一次被交互的时间戳与全局（`merge_actions`）最晚时间戳之间的时间差。

#### 5.3.8 会话末尾活动块特征 

每个 `session` 内，基于时间间隔（大于1小时）划分出的“活动块”（chunk）中的最后一个块的交互情况。(如果两个商品之间的时间间隔大于1小时，则将这两个商品分到不同的块中，从头开始划分)

49. `last_chunk_click` (float32): **末尾活动块点击数**: 在该 session 的最后一个活动块中，该 `aid` 被点击的次数。
50. `last_chunk_cart` (float32): **末尾活动块加购数**: 在该 session 的最后一个活动块中，该 `aid` 被加入购物车的次数。
51. `last_chunk_order` (float32): **末尾活动块下单数**: 在该 session 的最后一个活动块中，该 `aid` 被下单的次数。
52. `last_chunk_aid_total` (float32): **末尾活动块商品总交互数**: 在该 session 的最后一个活动块中，该 `aid` 的总交互次数 (click + cart + order)。
53. `max_chunk` (int32): **会话总活动块数**: 该 session 总共被划分成了多少个活动块（最后一个块的编号，从0或1开始计数）。
54. `session_counts_mean` (float32): **会话平均块内事件数**: 该 session 平均每个活动块包含多少次交互事件。
55. `last_chunk_total` (float32): **末尾活动块总交互数**: 该 session 的最后一个活动块中包含的所有 `aid` 的总交互次数。
56. `last_chunk_aid_ratio` (float32): **末尾活动块商品交互占比**: `last_chunk_aid_total / last_chunk_total`。该 `aid` 在末尾活动块的交互次数占该块总交互次数的比例。
57. `last_chunk_num` (int32): **商品块内最后交互排名**: 该 `aid` 在其出现的所有活动块中，最后一次出现的位置距离块内最后一个事件的排名（1 表示是该块的最后一个事件之一）。*（注意：合并逻辑基于 aid 在所有块中的最小逆序排名）* 

#### 5.3.9 用户-商品 交互特征

每个 `(session, aid)` 对在该特定会话内的详细交互统计。

58. `session_aid_total_action` (float32): **会话内商品总交互数**: 在该 session 中，该 `aid` 的总交互次数 (click + cart + order)。
59. `session_aid_share` (float32): **会话内商品交互占比**: `session_aid_total_action` / (该 session 的总交互次数)。
60. `session_aid_click_share` (float32): **会话内商品点击占比**: (在该 session 中该 `aid` 的点击次数) / `session_aid_total_action`。
61. `session_aid_cart_share` (float32): **会话内商品加购占比**: (在该 session 中该 `aid` 的加购次数) / `session_aid_total_action`。
62. `session_aid_order_share` (float32): **会话内商品下单占比**: (在该 session 中该 `aid` 的下单次数) / `session_aid_total_action`。
63. `last_1hour_clicks` (int, fillna(0)): **会话末尾1小时内点击数**: 在该 session 结束前的最后 1 小时内，该 `aid` 被点击的次数。
64. `last_1hour_carts` (int, fillna(0)): **会话末尾1小时内加购数**: 在该 session 结束前的最后 1 小时内，该 `aid` 被加入购物车的次数。
65. `last_1hour_orders` (int, fillna(0)): **会话末尾1小时内下单数**: 在该 session 结束前的最后 1 小时内，该 `aid` 被下单的次数。
66. `last_1day_clicks` (int, fillna(0)): **会话末尾1天内点击数**: 在该 session 结束前的最后 1 天内，该 `aid` 被点击的次数。
67. `last_1day_carts` (int, fillna(0)): **会话末尾1天内加购数**: 在该 session 结束前的最后 1 天内，该 `aid` 被加入购物车的次数。
68. `last_1day_orders` (int, fillna(0)): **会话末尾1天内下单数**: 在该 session 结束前的最后 1 天内，该 `aid` 被下单的次数。
69. `last_1week_clicks` (int, fillna(0)): **会话末尾1周内点击数**: 在该 session 结束前的最后 1 周内，该 `aid` 被点击的次数。
70. `last_1week_carts` (int, fillna(0)): **会话末尾1周内加购数**: 在该 session 结束前的最后 1 周内，该 `aid` 被加入购物车的次数。
71. `last_1week_orders` (int, fillna(0)): **会话末尾1周内下单数**: 在该 session 结束前的最后 1 周内，该 `aid` 被下单的次数。
72. `last_action_diff_hour` (float, fillna(0)): **商品末次交互距会话结束时间差 (小时)**: 在该 session 中，该 `aid` 最后一次被交互的时间与该 session 结束时间的时间差。

#### 5.3.10 会话聚合商品特征

将商品层级特征聚合到会话层级，计算会话中所有交互过的商品对应特征的平均值。

73. `session_click_cvr_unique` (float32): **会话商品平均点击 Session 占比 (对数值)**: 该 session 中所有交互过的 `aid` 的 `click_cvr_unique` 特征的平均值。反映该 session 触达的商品平均覆盖的会话比例（对数值）。
74. `session_cart_cvr_unique` (float32): **会话商品平均唯一会话加购转化率**: 该 session 中所有交互过的 `aid` 的 `cart_cvr_unique` 特征的平均值。反映该 session 交互的商品的平均“被加购倾向”。
75. `session_click_share_all` (float32): **会话商品平均全局点击份额**: 该 session 中所有交互过的 `aid` 的 `click_share_all` 特征的平均值。反映该 session 交互的商品平均流行程度（基于点击）。
76. `session_aid_rank_mean` (float32): **会话商品平均 Session 内排名**: 该 session 中所有交互过的 `aid` 的 `aid_rank_mean` 特征的平均值。反映该 session 交互的商品平均是在会话的早期还是晚期出现。

### 5.4 排序模型

使用 LightGBM (LGBMRanker) 训练排序模型，对召回阶段产生的候选商品 (`aid`) 针对每个用户会话 (`session`) 进行排序打分。目标是预测用户接下来最可能进行的行为（点击、加入购物车、下单），包含两个排序模型（v1 和 v2），它们在使用的特征集上有所区别。

**2. 模型差异**

- **V1模型**: 未使用bigram-feature，即session历史物品到候选order物品的共现分数的统计值，因此==**更专注于对于click类物品的排序预测。**==
- **V2模型**: **加入了 bigram 相关特征** ，==**V2利用商品序列共现信息来提升模型对于order类商品的排序预测，同时，cart类物品与order类物品存在相似性，因此也能够一定程度上提高模型对于cart类物品的排序预测。**==其他核心逻辑与 V1 相似。

**3. 核心工作流程**

两个版本都遵循相似的核心工作流程，主要包括以下步骤：

- **配置加载**:
  - 从 YAML 文件 (`feature_config.yaml`, `co_matrix_config.yaml`, `oof_config_vX.yaml`) 加载所需特征 (`FEATURES`) 列表、协同过滤矩阵配置 (`co_matrix_list`)、以及作为特征使用的其他模型 OOF 文件配置 (`oof_dict`)。
  - V2 版本在此步骤额外将 `bigram` 相关特征名添加到 `FEATURES` 列表中。
- **数据准备**:
  - **候选集采样 (`select_train_sample` 函数)**:
    - 采样所有正样本
    - 采样负样本，使得**正负样本比例为1:10**
  - **特征合并 (`join_features` 函数)**:
    - 这是核心的数据整合步骤，将大量预先计算好的特征合并到采样后的训练数据 (`session`, `aid` 对) 上。
- **模型训练 (`model_train` 函数)**:
  - **模型选择：** lightGBM ranker模型。
  - **交叉验证**: 使用5 折交叉验证。每一fold都训练得到一个模型
  - **cart与order模型增加特征：**cart模型将click模型与all模型的预测分数作为新的特征加入训练数据中进行训练，order模型将click、all和cart模型的预测分数作为特征加入训练数据中进行训练。
  - **最终模型：**对于每一类行为类型，由每个fold得到一个rank模型。
- **模型预测：**
  - **顺序：**按照click,all,cart,order的行为类型顺序进行模型预测，因为cart需要用到click和all的模型评分，order需要用到click、all和cart的模型评分。
  - **预测：**对于每一个行为类型，分别使用V1和V2各自的5个训练好的rank模型进行预测，然后取均值作为V1和V2模型预测的最终的分数。不使用其中最优的模型的原因是增强模型结果的泛化性。
- **模型融合：**将V1和V2的得分进行平均，得到每个session召回商品集中每个商品的最终得分，取每个session召回集中分数前20的商品作为最终预测结果。







